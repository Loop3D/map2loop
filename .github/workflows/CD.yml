name: release-please
on: [push, pull_request]

# cancel running jobs on new commit to PR
concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  linting:
    name: Linting
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install black ruff
      - name: Autoformat with black
        run: |
          black .
      - name: Lint with ruff
        run: |
          ruff check . --fix
      - name: Check for local changes
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            git config --global user.name "github-actions[bot]"
            git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
            git add .
            git commit -m "style: style fixes by ruff and autoformatting by black"
          fi
          
  conda-continuous-integration:
    name: Conda Continuous integration ${{ matrix.os }} Python ${{ fromJSON(vars.PYTHON_VERSIONS)}}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ windows-latest, ubuntu-latest, macos-latest ]
        python-version: ${{ fromJSON(vars.PYTHON_VERSIONS)}}
        triplet: [
          ./ci/custom-triplets/x64-osx-dynamic-release.cmake, 
          ./ci/custom-triplets/x64-linux-dynamic-release.cmake, 
          ./ci/custom-triplets/x64-windows-dynamic-release.cmake
          ]
    steps:
      - uses: actions/checkout@v4
      - uses: conda-incubator/setup-miniconda@v3
        with:
          python-version: ${{ matrix.python-version }}
      
      # Cache conda environments
      - name: Cache conda environment
        uses: actions/cache@v4
        with:
          path: ~/conda_pkgs_dir
          key: ${{ runner.os }}-conda-${{ matrix.python-version }}
          restore-keys: |
            ${{ runner.os }}-conda-

      - name: Installing dependencies
        shell: bash -l {0}
        run: |
          conda install -c loop3d -c conda-forge --file dependencies.txt -y
          conda install pytest -y

      - name: Building and install
        shell: bash -l {0}
        run: |
          pip install .

      - name: Testing
        shell: bash -l {0}
        run: |
          pytest

  documentation-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: |
          cp CHANGELOG.md docs/source/CHANGELOG.md
          docker build . -t=docs -f docs/Dockerfile 
          docker run -v $(pwd):/map2loop docs bash map2loop/docs/build_docs.sh
      - name: upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: docs
          path: docs/build/html

  release-please:
    runs-on: ubuntu-latest
    needs: conda-continuous-integration
    if: github.ref == 'refs/heads/master'
    steps:
      - uses: GoogleCloudPlatform/release-please-action@v4
        id: release
        with:
          release-type: python
          package-name: map2loop
          include-v-in-tag: false
    outputs:
      release_created: ${{ steps.release.outputs.release_created }}

  conda-build:
    name: Building conda package for python
    needs: "conda-continuous-integration"
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        os: ["ubuntu-latest"]
        python-version: ${{ fromJSON(vars.PYTHON_VERSIONS)}}
    steps:
      - uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          python-version: ${{ matrix.python-version }}

      - uses: actions/checkout@v4
      - name: update submodules
        #       shell: bash -l {0}
        run: |
          git submodule update --init --recursive
      - name: Conda build
        env:
          ANACONDA_API_TOKEN: ${{ secrets.ANACONDA_TOKEN  }}
        shell: bash -l {0}
        run: |
          conda install --solver=classic -c conda-forge conda-build anaconda-client conda-libmamba-solver -y
          conda build -c conda-forge -c loop3d --output-folder conda conda --python ${{ matrix.python-version }}
          conda convert -p all conda/linux-64/*.tar.bz2 -f -o conda

      - name: upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: conda-${{ matrix.os }}-${{ matrix.python-version }}
          path: conda
  
  build-sdist:
    name: Build Map2loop sdist
    runs-on: ubuntu-latest
    container:
      image: "ghcr.io/osgeo/gdal:ubuntu-small-3.9.2"
    steps:
      - uses: actions/checkout@v4
      
      - name: Install packages
        run: |
            apt-get update && apt-get install -y build-essential python3-dev
  
      - name: Build SDist
        run: |
          pip install build setuptools
          python -m build --sdist

      - uses: actions/upload-artifact@v4
        with:
          name: map2loop-dist
          path: dist/*.tar.gz
          compression-level: 0

  test-sdist:
    name: Test sdist
    needs: build-sdist
    runs-on: ubuntu-latest
    container:
      image: "ghcr.io/osgeo/gdal:ubuntu-small-3.9.2"

    steps:
      - name: Install packages
        run: |
          apt-get update && apt-get install -y build-essential python3-dev
          

      - name: Create virtual environment
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          . $HOME/.cargo/env
          uv venv .venv
          echo "VIRTUAL_ENV=.venv" >> $GITHUB_ENV
          echo "$PWD/.venv/bin" >> $GITHUB_PATH

      - name: Download sdist from artifacts
        uses: actions/download-artifact@v4
        with:
          name: map2loop-sdist
          path: wheelhouse

      - name: Build from sdist and install test dependencies
        shell: bash
        run: |
          uv pip install --no-cache wheelhouse/*.tar.gz
          uv pip install -r dependencies.txt
          uv pip list

      - name: Run tests
        shell: bash
        # virtual environment is automatically activated
        run: |
          cd ..
          uv run python -c "import map2loop; print(f'GDAL version: {map2loop.__gdal_version__}\nGEOS version: {map2loop.__gdal_geos_version__}')"
  
  build-wheels-linux:
    name: Build wheels on Linux
    runs-on: "ubuntu-latest"
    strategy:
      fail-fast: false
      matrix:
        include:
          # use manylinux_2_28 for any platforms with glibc>=2.28
          - wheel_name: "map2loop-wheel-linux-manylinux_2_28_x86_64"
            container: "./ci/manylinux_2_28_x86_64-vcpkg-gdal.Dockerfile"

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v3
        with:
          install: true
          buildkitd-flags: --debug

      - name: Build Docker image with vcpkg and gdal
        # using build-push-action (without push) to make use of cache arguments
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ${{ matrix.container }}
          tags: manylinux-vcpkg-gdal:latest
          push: false
          load: true
          cache-from: type=gha
          cache-to: type=gha,mode=max
        env:
          BUILDKIT_PROGRESS: plain

      - name: Build wheels
        uses: pypa/cibuildwheel@v2.21.1

      - uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.wheel_name }}
          path: ./wheelhouse/*.whl
          compression-level: 0

  build-wheels-mac-windows:
    name: Build wheels on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: "macos-latest"
            triplet: "x64-osx-dynamic-release"
            arch: x86_64
            vcpkg_cache: "/Users/runner/.cache/vcpkg/archives"
            vcpkg_logs: "/usr/local/share/vcpkg/buildtrees/**/*.log"

          - os: "windows-latest"
            triplet: "x64-windows-dynamic-release"
            arch: AMD64
            # windows requires windows-specific paths
            vcpkg_cache: "c:\\vcpkg\\installed"
            vcpkg_logs: "c:\\vcpkg\\buildtrees\\**\\*.log"

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Cache vcpkg
        uses: actions/cache@v4
        id: vcpkgcache
        with:
          path: |
            ${{ matrix.vcpkg_cache }}
          # bump the last digit to avoid using previous build cache
          key: ${{ matrix.os }}-vcpkg-gdal3.9.2-cache0

      # MacOS build requires aclocal, which is part of automake, but appears
      # to be missing in default image
      - name: Reinstall automake
        if: runner.os == 'macOS'
        run: |
          brew reinstall automake
          echo $(which aclocal)

      - name: Checkout specific version of vcpkg
        shell: bash
        run: |
          cd $VCPKG_INSTALLATION_ROOT
          # on mac the clone is not clean, otherwise git pull fails
          git reset --hard
          # pull specific commit with desired GDAL version
          git pull
          git checkout 73794ce5f63fd138fab999a22959ca7c6305d93c

      - name: Install GDAL
        env:
          VCPKG_DEFAULT_TRIPLET: ${{ matrix.triplet }}
        shell: bash
        run: |
          vcpkg install --overlay-triplets=./ci/custom-triplets --feature-flags="versions,manifests" --x-manifest-root=./ci --x-install-root=$VCPKG_INSTALLATION_ROOT/installed
          vcpkg list

      - name: Upload vcpkg build logs
        if: ${{ failure() }}
        uses: actions/upload-artifact@v4
        with:
          name: map2loop-vcpkg-logs-${{ matrix.triplet }}
          path: ${{ matrix.vcpkg_logs }}

      - name: Build wheels
        uses: pypa/cibuildwheel@v2.21.1
        env:
          # CIBW needs to know triplet for the correct install path
          VCPKG_DEFAULT_TRIPLET: ${{ matrix.triplet }}

      - uses: actions/upload-artifact@v4
        with:
          name: map2loop-wheel-${{ matrix.triplet }}
          path: ./wheelhouse/*.whl
          compression-level: 0
  #TODO: Continure from here        
  test-wheels:
    name: Test wheels on ${{ matrix.os }} (Python ${{ matrix.python-version }}}})
    needs: [build-wheels-linux, build-wheels-mac-windows]
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix: 
        os: ["ubuntu-latest", "windows-latest", "macos-latest"]
        python-version: ["3.8", "3.9", "3.10", "3.11", "3.12"]
        include:
          - os: "ubuntu-latest"
            artifact: map2loop-wheel-linux-manylinux_2_28_x86_64
          - os: "windows-latest"
            artifact: map2loop-wheel-x64-windows-dynamic-release
          - os: "macos-12"
            artifact: map2loop-wheel-x64-osx-dynamic-release

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          allow-prereleases: true

      - name: Create virtual environment (Linux / MacOS)
        # install uv and use it to create a virtual environment, then add it to
        # environment variables so that it is automatically activated and can be
        # used for tests below
        if: ${{ runner.os != 'Windows' }}
        shell: bash
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          . $HOME/.cargo/env
          uv venv .venv
          echo "VIRTUAL_ENV=.venv" >> $GITHUB_ENV
          echo "$PWD/.venv/bin" >> $GITHUB_PATH

      - name: Create virtual environment (Windows)
        if: ${{ runner.os == 'Windows' }}
        run: |
          irm https://astral.sh/uv/install.ps1 | iex
          uv venv .venv
          "VIRTUAL_ENV=.venv" | Out-File -FilePath $env:GITHUB_ENV -Append
          "$PWD/.venv/Scripts" | Out-File -FilePath $env:GITHUB_PATH -Append

      - name: Download wheels from artifacts
        uses: actions/download-artifact@v4
        with:
          name: ${{ matrix.artifact }}
          path: wheelhouse

      - name: Install dependencies and map2loop wheel
        shell: bash
        run: |
            uv pip install -r dependencies.txt
            uv pip install --no-cache --pre --no-index --find-links wheelhouse map2loop
            uv pip list

      - name: Run Wheel tests
        shell: bash
        # virtual environment is automatically activated
        run: |
          cd ..
          uv run python -c "import map2loop; print(f'GDAL version: {map2loop.__gdal_version__}\nGEOS version: {map2loop.__gdal_geos_version__}')"

  conda-deploy:
    #runs all the same as the build stage but need to rerun after release created to get updated
    #tag
    name: Building conda package for python
    needs: ["release-please", conda-build]
    if: ${{ needs.release-please.outputs.release_created }}

    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        os: ["ubuntu-latest"]
        python-version: ${{ fromJSON(vars.PYTHON_VERSIONS)}}
    steps:
      - uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          python-version: ${{ matrix.python-version }}

      - uses: actions/checkout@v4
      - name: update submodules
        #       shell: bash -l {0}
        run: |
          git submodule update --init --recursive
      - name: Conda build
        env:
          ANACONDA_API_TOKEN: ${{ secrets.ANACONDA_TOKEN  }}
        shell: bash -l {0}
        run: |
          conda install --solver=classic -c conda-forge conda-build anaconda-client conda-libmamba-solver -y
          conda build -c conda-forge -c loop3d --output-folder conda conda --python ${{ fromJSON(vars.PYTHON_VERSIONS)}}
          conda convert -p all conda/linux-64/*.tar.bz2 -f -o conda
          anaconda upload --label main conda/*/*.tar.bz2
  upload_to_pypi:
      runs-on: "ubuntu-latest"
      needs: ["release-please", build-sdist, test-sdist]
      if: ${{ needs.release-please.outputs.release_created }}
      permissions:
        # IMPORTANT: this permission is mandatory for trusted publishing
        id-token: write
      steps:
        - uses: actions/download-artifact@v4
          with:
            name: dist
            path: dist
        - uses: pypa/gh-action-pypi-publish@release/v1
          with:
            skip-existing: true
            verbose: true

  documentation-deploy:
    runs-on: ubuntu-latest
    needs: [release-please, documentation-test]
    if: ${{ needs.release-please.outputs.release_created }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: docs
          path: docs
      - name: ls
        run: |
          ls -l docs
      - name: Deploy 🚀
        uses: JamesIves/github-pages-deploy-action@v4
        with:
          branch: gh-pages # The branch the action should deploy to.
          folder: docs # The folder the action should deploy.
